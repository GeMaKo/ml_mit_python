{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 -- Introduction -- Classification with iris dataset\n",
    "based on https://machinelearningmastery.com/machine-learning-in-python-step-by-step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the versions of libraries\n",
    "    \n",
    "# Python version\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "\n",
    "# scipy\n",
    "import scipy\n",
    "print(f\"scipy: {scipy.__version__}\")\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"matplotlib: {matplotlib.__version__}\")\n",
    "\n",
    "#seaborn\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\")\n",
    "print(f\"seaborn: {sns.__version__}\")\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print(f\"sklearn: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 -- Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# also available in scikit learn: from sklearn.datasets import load_iris\n",
    "data = \"data/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "df = pd.read_csv(data, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "sns.scatterplot(x=\"sepal-length\", y=\"sepal-width\", hue=\"class\", s=80, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 -- Familiarize yourself with the data and data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(figsize=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature in df.columns[:-1]:\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(15,5))\n",
    "    \n",
    "    sns.boxplot(x=\"class\", y=feature, data=df, ax=ax[0])\n",
    "    \n",
    "    for i in range(3):\n",
    "        sns.distplot(df[df[\"class\"] == df[\"class\"].unique()[i]][feature], kde=True, color=[\"b\",\"orange\",\"green\"][i], ax=ax[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 -- Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = [\"petal-length\", \"petal-width\"]\n",
    "features = [\"sepal-length\", \"sepal-width\", \"petal-length\", \"petal-width\"]\n",
    "X = df[features]\n",
    "y = df[\"class\"]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model) -> list:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    \n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot Check Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "models = {}\n",
    "models['LR'] = LogisticRegression(solver='liblinear', multi_class='ovr', fit_intercept=True)\n",
    "models['LDA'] = LinearDiscriminantAnalysis()\n",
    "models['KNN'] = KNeighborsClassifier(3)\n",
    "models['CART'] = DecisionTreeClassifier()\n",
    "models['NB'] = GaussianNB()\n",
    "models['SVM'] = SVC(gamma='auto')\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models.items():\n",
    "    cv_results = train_model(model)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(f'{name} acc: {round(cv_results.mean(), 3)} (std: {round(cv_results.std(), 3)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.bar(names, np.mean(results, axis=1))\n",
    "plt.ylim([0.8, 1])\n",
    "\n",
    "plt.title(\"Training score of 6 different algorithms on iris dataset\")\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Algorithm Comparison')\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(models['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', multi_class='ovr').fit(X_train, Y_train)\n",
    "\n",
    "pd.DataFrame(model.coef_.reshape(-1, 3), columns=[model.classes_], index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 -- Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take best model and test it on the holdout test set\n",
    "model = SVC(gamma='auto').fit(X_train, Y_train)\n",
    "\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "Y_predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(f\"Accuracy on test set: {round(accuracy_score(Y_test, Y_predictions), 3)}\")\n",
    "print(f\"Confusion matrix:\\n {confusion_matrix(Y_test, Y_predictions)}\")\n",
    "print(f\"Classification report:\\n {classification_report(Y_test, Y_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb = LabelEncoder()\n",
    "\n",
    "# train on 2D data for plot\n",
    "# try different kernels: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "model = SVC(kernel='rbf', degree=1, gamma='auto').fit(X_train.values[:, 2:], Y_train)\n",
    "\n",
    "# create a mesh to plot in\n",
    "x_min, x_max = X_train.values[:, 2].min() - 1, X_train.values[:, 2].max() + 1\n",
    "y_min, y_max = X_train.values[:, 3].min() - 1, X_train.values[:, 3].max() + 1\n",
    "\n",
    "h = .02\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = lb.fit_transform(Z)\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.5)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X_train.values[:, 2], X_train.values[:, 3], c=lb.fit_transform(Y_train), s=50)\n",
    "plt.xlabel(features[2])\n",
    "plt.ylabel(features[3])\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 -- Regression\n",
    "data: https://stats.oecd.org/Index.aspx?DataSetCode=BLI#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli = pd.read_csv(\"data/oecd_bli_2020.csv\")\n",
    "\n",
    "oecd_bli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli.Measure.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli[oecd_bli.Country == 'Australia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli[(oecd_bli.Country == 'Australia') & (oecd_bli.Inequality == \"Total\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli_pivot = oecd_bli[oecd_bli.Inequality == \"Total\"].pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
    "\n",
    "oecd_bli_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli_pivot[\"Life satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "chart = sns.barplot(x='Country', y='Life satisfaction', data=oecd_bli_pivot.reset_index().sort_values('Life satisfaction', ascending=False))\n",
    "\n",
    "chart.set_xticklabels(chart.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = oecd_bli_pivot.drop(columns=[\"Life satisfaction\"])\n",
    "y = oecd_bli_pivot[\"Life satisfaction\"]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.plot(X['Household net adjusted disposable income'], y, \".\", markersize=20)\n",
    "\n",
    "plt.xlabel(\"Household net adjusted disposable income\")\n",
    "plt.ylabel(\"Life satisfaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oecd_bli_pivot[['Household net adjusted disposable income', 'Life satisfaction']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "clf = make_pipeline(\n",
    "    sklearn.impute.SimpleImputer(missing_values=np.nan, strategy='mean'), \n",
    "    sklearn.preprocessing.StandardScaler(), \n",
    "    #sklearn.ensemble.BaggingRegressor(base_estimator=sklearn.svm.SVR()),\n",
    "    #sklearn.ensemble.GradientBoostingRegressor(loss='ls', n_estimators=20, max_depth=2, learning_rate=0.1),\n",
    "    #sklearn.neighbors.KNeighborsRegressor(n_neighbors=3),\n",
    "    sklearn.linear_model.Ridge()\n",
    ")\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "\n",
    "scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.Ridge()\n",
    "imp = sklearn.impute.SimpleImputer()\n",
    "mms = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "imp.fit(X_train)\n",
    "mms.fit(imp.transform(X_train))\n",
    "\n",
    "model.fit(mms.transform(imp.transform(X_train)), y_train)\n",
    "\n",
    "y_pred = model.predict(mms.transform(imp.transform(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.bar(X_test.index, (y_test - y_pred)**2)\n",
    "\n",
    "plt.ylabel('squared error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.plot(X_test['Household net adjusted disposable income'], y_test, \".\", markersize=20, label='true')\n",
    "plt.plot(X_test['Household net adjusted disposable income'], y_pred, \".\", markersize=10, label='pred')\n",
    "\n",
    "for i, e in enumerate(X_test.iterrows()):\n",
    "    country, row = e\n",
    "    x = row['Household net adjusted disposable income']\n",
    "    y = y_test[country]\n",
    "    \n",
    "    plt.annotate(country, xy=(x,y), xytext=(0, 10), textcoords=\"offset points\", ha='center')\n",
    "    plt.plot([x, x], [y, y_pred[i]], color=\"red\", zorder=0, linewidth=1)\n",
    "\n",
    "plt.xlabel(\"Household net adjusted disposable income\")\n",
    "plt.ylabel(\"Life satisfaction\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 -- Improve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = oecd_bli_pivot.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "#mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "mask = np.diag(np.ones_like(corr.iloc[:,0]))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr['Life satisfaction'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = oecd_bli_pivot.corr(method='spearman')\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "#mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "mask = np.diag(np.ones_like(corr.iloc[:,0]))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr['Life satisfaction'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.linear_model.Ridge()\n",
    "imp = sklearn.impute.SimpleImputer()\n",
    "mms = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "imp.fit(X_train[features])\n",
    "mms.fit(imp.transform(X_train[features]))\n",
    "\n",
    "model.fit(mms.transform(imp.transform(X_train[features])), y_train)\n",
    "\n",
    "y_pred = model.predict(mms.transform(imp.transform(X_test[features])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.bar(X_test.index, (y_test - y_pred)**2)\n",
    "\n",
    "plt.ylabel('squared error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    plt.figure(figsize=(15, 8))\n",
    "\n",
    "    plt.plot(X_test[feature], y_test, \".\", markersize=20, label='true')\n",
    "    plt.plot(X_test[feature], y_pred, \".\", markersize=10, label='pred')\n",
    "\n",
    "    for i, e in enumerate(X_test.iterrows()):\n",
    "        country, row = e\n",
    "        x = row[feature]\n",
    "        y = y_test[country]\n",
    "\n",
    "        plt.annotate(country, xy=(x,y), xytext=(0, 10), textcoords=\"offset points\", ha='center')\n",
    "        plt.plot([x, x], [y, y_pred[i]], color=\"red\", zorder=0, linewidth=1)\n",
    "\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Life satisfaction\")\n",
    "    plt.legend(loc=\"best\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
