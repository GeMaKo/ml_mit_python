{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metriken Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten einlesen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der verwendete Datensatz enthält Kreditkartentransaktionen die innerhalb der Variable `class` mit 1 gekennzeichnet sind, wenn es sich um einen Betrugsfall handelt. `time` gibt in Sekunden den Abstand zum Beginn des Beobachtungszeitraums an und `amount` die Höhe der Transaktion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust to correct path if necessary\n",
    "creditcard_df = pd.read_csv('credit_card_fraud.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Überblick über Daten bekommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   amount  class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bis auf `time` und `amount` wurden alle Variablen durch Principale Component Analysis gewonnen (PCA) um Anonymität zu gewährleisten. Das erklärt Durchschnittswerte von 0 und die abnehmenden Standardabweichungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "      <td>284807.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>88.35</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.15</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.33</td>\n",
       "      <td>250.12</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-56.41</td>\n",
       "      <td>-72.72</td>\n",
       "      <td>-48.33</td>\n",
       "      <td>-5.68</td>\n",
       "      <td>-113.74</td>\n",
       "      <td>-26.16</td>\n",
       "      <td>-43.56</td>\n",
       "      <td>-73.22</td>\n",
       "      <td>-13.43</td>\n",
       "      <td>-24.59</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>-18.68</td>\n",
       "      <td>-5.79</td>\n",
       "      <td>-19.21</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>-14.13</td>\n",
       "      <td>-25.16</td>\n",
       "      <td>-9.50</td>\n",
       "      <td>-7.21</td>\n",
       "      <td>-54.50</td>\n",
       "      <td>-34.83</td>\n",
       "      <td>-10.93</td>\n",
       "      <td>-44.81</td>\n",
       "      <td>-2.84</td>\n",
       "      <td>-10.30</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>-22.57</td>\n",
       "      <td>-15.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.50</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>5.60</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.50</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>77.16</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.00</td>\n",
       "      <td>2.45</td>\n",
       "      <td>22.06</td>\n",
       "      <td>9.38</td>\n",
       "      <td>16.88</td>\n",
       "      <td>34.80</td>\n",
       "      <td>73.30</td>\n",
       "      <td>120.59</td>\n",
       "      <td>20.01</td>\n",
       "      <td>15.59</td>\n",
       "      <td>23.75</td>\n",
       "      <td>12.02</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.13</td>\n",
       "      <td>10.53</td>\n",
       "      <td>8.88</td>\n",
       "      <td>17.32</td>\n",
       "      <td>9.25</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.59</td>\n",
       "      <td>39.42</td>\n",
       "      <td>27.20</td>\n",
       "      <td>10.50</td>\n",
       "      <td>22.53</td>\n",
       "      <td>4.58</td>\n",
       "      <td>7.52</td>\n",
       "      <td>3.52</td>\n",
       "      <td>31.61</td>\n",
       "      <td>33.85</td>\n",
       "      <td>25691.16</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time         V1         V2         V3         V4         V5  \\\n",
       "count  284807.00  284807.00  284807.00  284807.00  284807.00  284807.00   \n",
       "mean    94813.86       0.00       0.00      -0.00       0.00       0.00   \n",
       "std     47488.15       1.96       1.65       1.52       1.42       1.38   \n",
       "min         0.00     -56.41     -72.72     -48.33      -5.68    -113.74   \n",
       "25%     54201.50      -0.92      -0.60      -0.89      -0.85      -0.69   \n",
       "50%     84692.00       0.02       0.07       0.18      -0.02      -0.05   \n",
       "75%    139320.50       1.32       0.80       1.03       0.74       0.61   \n",
       "max    172792.00       2.45      22.06       9.38      16.88      34.80   \n",
       "\n",
       "              V6         V7         V8         V9        V10        V11  \\\n",
       "count  284807.00  284807.00  284807.00  284807.00  284807.00  284807.00   \n",
       "mean        0.00      -0.00       0.00      -0.00       0.00       0.00   \n",
       "std         1.33       1.24       1.19       1.10       1.09       1.02   \n",
       "min       -26.16     -43.56     -73.22     -13.43     -24.59      -4.80   \n",
       "25%        -0.77      -0.55      -0.21      -0.64      -0.54      -0.76   \n",
       "50%        -0.27       0.04       0.02      -0.05      -0.09      -0.03   \n",
       "75%         0.40       0.57       0.33       0.60       0.45       0.74   \n",
       "max        73.30     120.59      20.01      15.59      23.75      12.02   \n",
       "\n",
       "             V12        V13        V14        V15        V16        V17  \\\n",
       "count  284807.00  284807.00  284807.00  284807.00  284807.00  284807.00   \n",
       "mean       -0.00       0.00       0.00       0.00       0.00      -0.00   \n",
       "std         1.00       1.00       0.96       0.92       0.88       0.85   \n",
       "min       -18.68      -5.79     -19.21      -4.50     -14.13     -25.16   \n",
       "25%        -0.41      -0.65      -0.43      -0.58      -0.47      -0.48   \n",
       "50%         0.14      -0.01       0.05       0.05       0.07      -0.07   \n",
       "75%         0.62       0.66       0.49       0.65       0.52       0.40   \n",
       "max         7.85       7.13      10.53       8.88      17.32       9.25   \n",
       "\n",
       "             V18        V19        V20        V21        V22        V23  \\\n",
       "count  284807.00  284807.00  284807.00  284807.00  284807.00  284807.00   \n",
       "mean        0.00       0.00       0.00       0.00      -0.00       0.00   \n",
       "std         0.84       0.81       0.77       0.73       0.73       0.62   \n",
       "min        -9.50      -7.21     -54.50     -34.83     -10.93     -44.81   \n",
       "25%        -0.50      -0.46      -0.21      -0.23      -0.54      -0.16   \n",
       "50%        -0.00       0.00      -0.06      -0.03       0.01      -0.01   \n",
       "75%         0.50       0.46       0.13       0.19       0.53       0.15   \n",
       "max         5.04       5.59      39.42      27.20      10.50      22.53   \n",
       "\n",
       "             V24        V25        V26        V27        V28     amount  \\\n",
       "count  284807.00  284807.00  284807.00  284807.00  284807.00  284807.00   \n",
       "mean        0.00       0.00       0.00      -0.00      -0.00      88.35   \n",
       "std         0.61       0.52       0.48       0.40       0.33     250.12   \n",
       "min        -2.84     -10.30      -2.60     -22.57     -15.43       0.00   \n",
       "25%        -0.35      -0.32      -0.33      -0.07      -0.05       5.60   \n",
       "50%         0.04       0.02      -0.05       0.00       0.01      22.00   \n",
       "75%         0.44       0.35       0.24       0.09       0.08      77.16   \n",
       "max         4.58       7.52       3.52      31.61      33.85   25691.16   \n",
       "\n",
       "           class  \n",
       "count  284807.00  \n",
       "mean        0.00  \n",
       "std         0.04  \n",
       "min         0.00  \n",
       "25%         0.00  \n",
       "50%         0.00  \n",
       "75%         0.00  \n",
       "max         1.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = creditcard_df.loc[:, 'time':'amount'].values\n",
    "y = creditcard_df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=0) \n",
    "\n",
    "train_id, test_id = next(strat_split.split(X, y))\n",
    "X_train, X_test, y_train, y_test = X[train_id], X[test_id], y[train_id], y[test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing values for logistic regression for faster conversion\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelle trainieren und Vorhersagen erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save probility estimates of model\n",
    "y_pred_lr = lr_model.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, min_samples_split=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(min_samples_split=50)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Baseline wählen wir einfach die häufigste Ausprägung der Zielvariable: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_baseline = np.zeros(y_test.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sind Sie gefragt. Berechnen Sie nachfolgend die gefragten Metriken und vergleichen Sie die Modelle miteinander und der Baseline. \n",
    "\n",
    "Übersichtstabelle:\n",
    "|True / Pred          |  Negative  |  Positive  |\n",
    "| ---      |    :---:   |    :---:   |\n",
    "| Negative |     TN     |     FP     |\n",
    "| Positive |     FN     |     TP     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {'lr': y_pred_lr, 'rf': y_pred_rf, 'baseline': y_baseline}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nutzen Sie die `accuracy_score` Funktion zum Berechnen der Accuracy. Beachten Sie, dass diese Funktion KLassen, also ganze Zahlen, als Inputs benötigt. Vergleichen Sie anschließend die Scores der verschiedenen Vorhersagen. Wie aussagekräftig sind sie? \n",
    "$$ Accuracy = \\frac{True \\: Values}{All \\: Values} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.999184, 'rf': 0.999333, 'baseline': 0.998271}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores = {model: accuracy_score(y_test, y_pred.round()).round(6) for model, y_pred in predictions.items()}\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da die überwältigende Mehrheit der Werte 0 ist, sagen Modelle und Baseline in den meisten oder allen Fällen auch 0 vorher. Da die Accuracy nicht zwischen negativen und positiven Werten bzw. 0 und 1 unterscheidet, sondern nur alle richtig vorhergesagten Werte mit der Gesamtzahl an Werten ins Verhältnis setzt, liegen die Scores der verschiedenen Methoden sehr nah bei einander. Daran kann man sehen, dass Accuracy keine geeignete Metrik bei einer unsymetrischen Verteilung der Zielvariablenwerte ist.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative:\n",
    "# acc_lr = accuracy_score(y_test, y_pred_lr.round())\n",
    "# print(acc_lr.round(6))\n",
    "\n",
    "# acc_rf = accuracy_score(y_test, y_pred_rf.round())\n",
    "# print(acc_rf.round(6))\n",
    "\n",
    "# acc_baseline = accuracy_score(y_test, y_baseline)\n",
    "# print(acc_baseline.round(6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Area under the ROC curve (AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Die ROC (Receiver Operating Characteristic) Curve zeichnet für jeden KLassifizierungsschwellenwert die True-Positive-Rate (TPR, auch Recall genannt) und die False-Positive-Rate (FPR) in einen Graphen. Die Area Under the Curve (AUC) berechnet dann die Fläche unter der Kurve, die ein Maxium von 1 hat und bei Zufallswerten den Wert 0.5 erreicht. Im Gegensatz zu den anderen präsentierten Metriken, verwendet die AUC die Wahrscheinlichkeitsschätzungen und nicht die daraus folgenden KLassen.\n",
    "\n",
    "Berechnen Sie mit Hilfe der Funktion `roc_auc_score` die AUC für alle 3 Vorhersagen. Welche Unterschiede bemerken Sie?\n",
    "$$ TPR = \\frac{TP}{TP + FN} $$ \n",
    "$$ FPR = \\frac{FP}{FP + TN} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.97128, 'rf': 0.969474, 'baseline': 0.5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores = {model: roc_auc_score(y_test, y_pred).round(6) for model, y_pred in predictions.items()}\n",
    "auc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Gegensatz zur Accuracy Metrik, schneidet die Baseline hier deutlich schlechter ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative:\n",
    "# auc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "# print(auc_lr.round(6))\n",
    "\n",
    "# auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "# print(auc_rf.round(6))\n",
    "\n",
    "# auc_baseline = roc_auc_score(y_test, y_baseline)\n",
    "# print(auc_baseline.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Versuchen Sie auch die ROC Curve zu plotten. Mit `roc_curve` lassen sich die FPR und TPR Werte berechnen und dann mit `plt.plot` plotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_pred_lr)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(fpr_lr, tpr_lr, color='slateblue', label=f'LR (AUC: {auc_scores[\"lr\"].round(3)})')\n",
    "ax.plot(fpr_rf, tpr_rf, color='darkred', label=f'RF (AUC: {auc_scores[\"rf\"].round(3)})')\n",
    "ax.plot([0,1], [0,1], color='black', linestyle='dashed', label='Random')\n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('ROC Curve')\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Precission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precission (dt. Genauigkeit) gibt den Anteil relevanter positver Klassifizierungen (TP) an allen positiv klassifizierten Elementen an.\n",
    "\n",
    "Nutzen Sie die Funktion `precision_score` um die Precision zu berechnen. Achten Sie dabei darauf, dass hier wieder Klassen und keine Wahrscheinlichkeitswerte gefragt sind.\n",
    "$$ Precission = \\frac{TP}{TP + FP} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tokr/miniconda3/envs/standard_ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr': 0.871429, 'rf': 0.871166, 'baseline': 0.0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_scores = {model: precision_score(y_test, y_pred.round()).round(6) for model, y_pred in predictions.items()}\n",
    "precision_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative:\n",
    "# precision_lr = precision_score(y_test, y_pred_lr.round())\n",
    "# print(precision_lr.round(6))\n",
    "\n",
    "# precision_rf = precision_score(y_test, y_pred_rf.round())\n",
    "# print(precision_rf.round(6))\n",
    "\n",
    "# precision_baseline = precision_score(y_test, y_baseline)\n",
    "# print(precision_baseline.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (dt. Trefferquote) gibt den Anteil relevanter positiver Klassifizierungen an allen tatsächlich positiven Elementen an.\n",
    "\n",
    "Nutzen Sie die Funktion `recall_score` um den Recall zu berechnen.\n",
    "$$ Recall = \\frac{TP}{TP + FN} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.619289, 'rf': 0.720812, 'baseline': 0.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_scores = {model: recall_score(y_test, y_pred.round()).round(6) for model, y_pred in predictions.items()}\n",
    "recall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative:\n",
    "# recall_lr = recall_score(y_test, y_pred_lr.round())\n",
    "# print(recall_lr.round(6))\n",
    "\n",
    "# recall_rf = recall_score(y_test, y_pred_rf.round())\n",
    "# print(recall_rf.round(6))\n",
    "\n",
    "# recall_baseline = precision_score(y_test, y_baseline)\n",
    "# print(recall_baseline.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der F1-Score kombiniert Precision und Recall in einer Metrik.\n",
    "\n",
    "Berechnen Sie den F1-Score mit Hilfe der Funktion `f1_score`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ F1 \\, Score = 2 * \\frac{precision * recall}{precision + recall} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.724036, 'rf': 0.788889, 'baseline': 0.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores = {model: f1_score(y_test, y_pred.round()).round(6) for model, y_pred in predictions.items()}\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative:\n",
    "# f1_lr = f1_score(y_test, y_pred_lr.round())\n",
    "# print(f1_lr.round(6))\n",
    "\n",
    "# f1_rf = f1_score(y_test, y_pred_rf.round())\n",
    "# print(f1_rf.round(6))\n",
    "\n",
    "# f1_baseline = f1_score(y_test, y_baseline)\n",
    "# print(f1_baseline.round(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere Methode Ergebnisse zu  betrachten, ist die Confusion Matrix. Sie bietet eine Möglichkeit die Anzahl an TruePositive, FalsePositive, TrueNegative und FalseNegative Werten auf einen Blick miteinander zu vergleichen. Verwenden Sie die `confusion_matrix` Funktion um sie zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Logistic Regression -------\n",
      "        predicted 0  predicted 1\n",
      "true 0       113708           18\n",
      "true 1           75          122\n",
      "---------- Random Forest ----------\n",
      "        predicted 0  predicted 1\n",
      "true 0       113705           21\n",
      "true 1           55          142\n",
      "------------ Baseline  ------------\n",
      "        predicted 0  predicted 1\n",
      "true 0       113726            0\n",
      "true 1          197            0\n"
     ]
    }
   ],
   "source": [
    "print('------- Logistic Regression -------')\n",
    "confusion_matrix_lr = pd.DataFrame(confusion_matrix(y_test, y_pred_lr.round()), index=['true 0', 'true 1'], columns=['predicted 0', 'predicted 1'])\n",
    "print(confusion_matrix_lr)\n",
    "\n",
    "print('---------- Random Forest ----------')\n",
    "confusion_matrix_rf = pd.DataFrame(confusion_matrix(y_test, y_pred_rf.round()), index=['true 0', 'true 1'], columns=['predicted 0', 'predicted 1'])\n",
    "print(confusion_matrix_rf)\n",
    "\n",
    "print('------------ Baseline  ------------')\n",
    "confusion_matrix_baseline = pd.DataFrame(confusion_matrix(y_test, y_baseline.round()), index=['true 0', 'true 1'], columns=['predicted 0', 'predicted 1'])\n",
    "print(confusion_matrix_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Abschließender Vergleich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vergleichen Sie nun noch einmal die Werte aller Metriken miteinander. Welches Modell würden Sie wählen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>auc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.999184</td>\n",
       "      <td>0.971280</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.619289</td>\n",
       "      <td>0.724036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.969474</td>\n",
       "      <td>0.871166</td>\n",
       "      <td>0.720812</td>\n",
       "      <td>0.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.998271</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc       auc  precision    recall  f1-score\n",
       "lr        0.999184  0.971280   0.871429  0.619289  0.724036\n",
       "rf        0.999333  0.969474   0.871166  0.720812  0.788889\n",
       "baseline  0.998271  0.500000   0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics_comparison = pd.DataFrame({'acc': acc_scores, 'auc': auc_scores, 'precision': precision_scores, 'recall': recall_scores, 'f1-score': f1_scores })\n",
    "model_metrics_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was Accuracy, AUC und Precision angeht, gleichen sich die Ergebnisse beider Modelle recht stark. Der große Unterschied liegt im Recall und darauß folgend auch dem F1-Score. Da es für eine Bank wichtig ist möglichst viele Betrugsfälle zu finden, scheint es logisch das Random Forest Modell zu wählen, das mehr der Betrugsfälle findet als die Logistic Regression. Dies lässt sich auch aus dem True Positive Feld der Confusion Matrix erkennen. Allerdings kann es auch Gründe geben trotzdem sich für die Logistic Regression zu entscheide. Bspw. benötigt das Training der LR nur einen Bruchteil der Zeit des Trainings eines RF-Modells, was bei noch deutlich größeren Datensätzen von Relevanz sein kann. \n",
    "\n",
    "Beachten Sie auch, dass wir der Einfachheit halber hier einige Aspekte ignorieren. Bspw. wird in diesen Kontexten häufig mit Kostenfunktionen gearbeitet die Klassifizierungen mit unterschiedlichen Kosten gewichten. Außerdem könnte man insbesondere den Recall Score dadurch beeinflussen, dass man Wahrscheinlichkeitsschätzwerte nicht, wie hier getan, bei 0.5 sondern einer niedrigeren Stelle aufrundet. Dies müsste dann allerdings mit einem extra Testset kalibriert werden.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "847f47a0c0153fc0b99df8d02507e943cdc2fd03c49260317bbd654755eb45e4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('standard_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
