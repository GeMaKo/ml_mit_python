{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://elitedatascience.com/python-cheat-sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data \n",
    "\n",
    "```PYTHON\n",
    "pd.read_csv(filename) # From a CSV file\n",
    "pd.read_table(filename) # From a delimited text file (like TSV)\n",
    "pd.read_excel(filename) # From an Excel file\n",
    "pd.read_sql(query, connection_object) # Reads from a SQL table/database\n",
    "pd.read_json(json_string) # Reads from a JSON formatted string, URL or file.\n",
    "pd.read_html(url) # Parses an html URL, string or file and extracts tables to a list of dataframes\n",
    "pd.read_clipboard() # Takes the contents of your clipboard and passes it to read_table()\n",
    "pd.DataFrame(dict) # From a dict, keys for columns names, values for data as lists\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://corgis-edu.github.io/corgis/datasets/csv/earthquakes/earthquakes.csv'\n",
    "df = pd.read_csv(dataset_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data \n",
    "\n",
    "```PYTHON\n",
    "df.shape() # Prints number of rows and columns in dataframe\n",
    "df.head(n) # Prints first n rows of the DataFrame\n",
    "df.tail(n) # Prints last n rows of the DataFrame\n",
    "df.sample(n) # return random samples from DataFrame\n",
    "df.info() # Index, Datatype and Memory information\n",
    "df.describe() # Summary statistics for numerical columns\n",
    "s.value_counts(dropna=False) # Views unique values and counts\n",
    "df.mean() # Returns the mean of all columns\n",
    "df.corr() # Returns the correlation between columns in a DataFrame\n",
    "df.count() # Returns the number of non-null values in each DataFrame column\n",
    "df.max() # Returns the highest value in each column\n",
    "df.min() # Returns the lowest value in each column\n",
    "df.median() # Returns the median of each column\n",
    "df.std() # Returns the standard deviation of each column\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"impact.magnitude\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting\n",
    "\n",
    "```PYTHON\n",
    "df[col] # Returns column with label col as Series\n",
    "df[[col]] # Returns column as DataFrame\n",
    "df[[col1, col2]] # Returns Columns as a new DataFrame\n",
    "s.iloc[0] # Selection by position (selects first element)\n",
    "s.loc[0] # Selection by index (selects element at index 0)\n",
    "df.iloc[0,:] # First row\n",
    "df.iloc[0,0] # First element of first column\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"impact.magnitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"impact.magnitude\", \"time.year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0,:] # first row, all columns, identical with df.iloc[0] \n",
    "df.iloc[:, 0] # first column, all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"impact.magnitude\"]. # all rows, column with name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning \n",
    "\n",
    "```PYTHON\n",
    "df.columns = ['a','b','c'] # Renames columns\n",
    "df.isnull() # Checks for null Values, Returns Boolean Array\n",
    "df.notnull() # Opposite of df.isnull()\n",
    "df.dropna() # Drops all rows that contain null values\n",
    "df.dropna(axis=1) # Drops all columns that contain null values\n",
    "df.dropna(axis=1,thresh=n) # Drops all rows have have less than n non null values\n",
    "df.fillna(x) # Replaces all null values with x\n",
    "s.fillna(s.mean()) # Replaces all null values with the mean (mean can be replaced with almost any function from the statistics section)\n",
    "s.astype(float) # Converts the datatype of the series to float\n",
    "s.replace(1,'one') # Replaces all values equal to 1 with 'one'\n",
    "s.replace([1,3],['one','three']) # Replaces all 1 with 'one' and 3 with 'three'\n",
    "df.rename(columns=lambda x: x + 1) # Mass renaming of columns\n",
    "df.rename(columns={'old_name': 'new_ name'}) # Selective renaming\n",
    "df.set_index('column_one') # Changes the index\n",
    "df.rename(index=lambda x: x + 1) # Mass renaming of index\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.sample(42).index] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.isnull().any(axis=1)]  # negate condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.dropna(how=\"all\").shape  # any drops row as soon as there is one na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"location.full\"].fillna(\"\").str.contains(\"Alaska\")].replace(\"Alaska\", \"ALASKA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"location.full\": \"location_full\"}).location_full  # now dot access is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"time.year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index([\"time.year\", \"time.month\", \"time.day\"]).loc[2016.0, 7.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter, Sort and Group By\n",
    "\n",
    "```PYTHON\n",
    "df[df[col] > 0.5] # Rows where the col column is greater than 0.5\n",
    "df[(df[col] > 0.5) & (df[col] < 0.7)] # Rows where 0.5 < col < 0.7\n",
    "df.sort_values(col1) # Sorts values by col1 in ascending order\n",
    "df.sort_values(col2,ascending=False) # Sorts values by col2 in descending order\n",
    "df.sort_values([col1,col2], ascending=[True,False]) # Sorts values by col1 in ascending order then col2 in descending order\n",
    "df.groupby(col) # Returns a groupby object for values from one column\n",
    "df.groupby([col1,col2]) # Returns a groupby object values from multiple columns\n",
    "df.groupby(col1)[col2].mean() # Returns the mean of the values in col2, grouped by the values in col1 (mean can be replaced with almost any function from the statistics section)\n",
    "df.pivot_table(index=col1, values= col2,col3], aggfunc=mean) # Creates a pivot table that groups by col1 and calculates the mean of col2 and col3\n",
    "df.groupby(col1).agg(np.mean) # Finds the average across all columns for every unique column 1 group\n",
    "df.apply(np.mean) # Applies a function across each column\n",
    "df.apply(np.max, axis=1) # Applies a function across each row\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"impact.magnitude\"] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"impact.magnitude\"] > 3) & (df[\"location.full\"].str.contains(\"Alaska\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"impact.magnitude\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"time.month\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining and Combining\n",
    "\n",
    "```PYTHON\n",
    "df1.append(df2) # Adds the rows in df1 to the end of df2 (columns should be identical)\n",
    "pd.concat([df1, df2],axis=1) # Adds the columns in df1 to the end of df2 (rows should be identical)\n",
    "df1.join(df2,on=col1,how='inner') # SQL-style joins the columns in df1 with the columns on df2 where the rows for col have identical values. how can be one of 'left', 'right', 'outer', 'inner'<strong> </strong>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.iloc[:10,:]\n",
    "df2 = df.iloc[10:20,:]\n",
    "\n",
    "df1.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.join(df2, on=\"impact.magnitude\", how=\"left\", lsuffix=\"df1\", rsuffix=\"df2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data\n",
    "\n",
    "```PYTHON\n",
    "df.to_csv(filename) # Writes to a CSV file\n",
    "df.to_excel(filename) # Writes to an Excel file\n",
    "df.to_sql(table_name, connection_object) # Writes to a SQL table\n",
    "df.to_json(filename) # Writes to a file in JSON format\n",
    "df.to_html(filename) # Saves as an HTML table\n",
    "df.to_clipboard() # Writes to the clipboard\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(df.iloc[:10].to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, plot_roc_curve\n",
    "from sklearn.externals import joblib \n",
    " \n",
    "# Load red wine data.\n",
    "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "data = pd.read_csv(dataset_url, sep=';')\n",
    " \n",
    "# Split data into training and test sets\n",
    "y = data.quality\n",
    "X = data.drop('quality', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=123, \n",
    "    stratify=y\n",
    ")\n",
    " \n",
    "# Declare data preprocessing steps\n",
    "pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))\n",
    " \n",
    "# Declare hyperparameters to tune\n",
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "                  'randomforestregressor__max_depth': [None, 5, 3, 1]}\n",
    " \n",
    "# Tune model using cross-validation pipeline\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=5)\n",
    " \n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "# Refit on the entire training set\n",
    "# No additional code needed if clf.refit == True (default is True)\n",
    " \n",
    "# Evaluate model pipeline on test data\n",
    "pred = clf.predict(X_test)\n",
    "print(\"R2: \", r2_score(y_test, pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, pred))\n",
    " \n",
    "# Save model for future use\n",
    "joblib.dump(clf, 'rf_regressor.pkl')\n",
    "# To load: clf2 = joblib.load('rf_regressor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz# Export as dot file\n",
    "\n",
    "export_graphviz(clf.best_estimator_.steps[1][1].estimators_[0], \n",
    "                out_file='tree.dot', \n",
    "                feature_names = data.drop('quality', axis=1).columns,\n",
    "                class_names = data.quality.name,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.steps[1][1].estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
